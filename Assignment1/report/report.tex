\documentclass{article}

\usepackage[a4paper,left=1cm,right=1.5cm,top=1cm,bottom=2cm]{geometry}
\usepackage[T2A]{fontenc}

\usepackage{indentfirst}
\usepackage{enumitem}

\usepackage{xcolor}
\definecolor{lightgray}{rgb}{0.83, 0.83, 0.83}
\definecolor{limegreen}{rgb}{0.2, 0.8, 0.2}
\definecolor{indigo(dye)}{rgb}{0.0, 0.25, 0.42}
\definecolor{indiagreen}{rgb}{0.07, 0.53, 0.03}
\definecolor{mikadoyellow}{rgb}{1.0, 0.77, 0.05}
\definecolor{navyblue}{rgb}{0.0, 0.0, 0.5}
\definecolor{oucrimsonred}{rgb}{0.6, 0.0, 0.0}
\definecolor{persianindigo}{rgb}{0.2, 0.07, 0.48}

\usepackage{tkz-euclide}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{float}
\usepackage{svg}

\usepackage{amsmath}
\usepackage{amsfonts}

\usepackage[thinlines]{easytable}
\usepackage{multirow}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=blue,
    linkcolor=blue,
    urlcolor=blue
}


\title{Assignment 1 - Report}
\author{Dmitriy Okoneshnikov, B22-CS-01 \\ \href{mailto:d.okoneshnikov@innopolis.university}{d.okoneshnikov@innopolis.university} \\ \url{https://codeforces.com/profile/magicwinnie}}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Algorithm flow}
The general idea for both of my algorithms is following:
\begin{enumerate}
    \item Explore the map without picking up the Shield
    \item Explore the map going through the cell with the Shield
    \item Compare the two distances and choose the shortest
\end{enumerate}
\subsection{Backtracking search}
Submission: \url{https://codeforces.com/group/ux8yi0gQhD/contest/479327/submission/231522968}

For backtracking I have used a modified version of Depth-First Search (described on lecture 5).
Standard DFS was changed to allow the search of all paths rather than finding the first path to the goal.
Some optimizations related to cutting off paths with worse distances to a cell were used.
Also neighbours of a cell are visited in such order that those that are closer to the goal are visited first.
All the information about the characters is stored in a map.

I start off by finding the shortest path (if any) from the start to the goal without picking up the Shield as it would be with us until the end of the test.
If the Shield was found and it is accessible, then I move to the cell with it and run the algorithm once again to find the shortest path from the Shield to the goal. 
Finally, I compare the paths and find the shortest one.

The information about Thanos' perception is used to build perception zones of enemies, and, therefore, decrease number of cells to check.
\subsection{A* search}
Submission: \url{https://codeforces.com/group/ux8yi0gQhD/contest/479327/submission/231523695}

For A* I have used the algorithm described in Wikipedia (\url{https://en.wikipedia.org/wiki/A*_search_algorithm#Pseudocode}). The only change in the algorithm was to prevent teleportation: for each step I move back the interactor to the start and move from there to the new cell.
All the information about the characters is stored in a map.

I start of by running A* to the Stone. If the Shield was found and can be reached then I run A* to the Shield and from it to the goal.
Finally, I find the shortest path among the two.

The information about Thanos' perception is used to build perception zones of enemies, and, therefore, decrease number of cells to check.

\section{Statistical comparison}
For generating maps and running the solutions on them, a generator and an interactor scripts were written by me and tested by Matvey Korinenko. Note that these scripts were shared with other students. They can be found in the following Github Gist: \url{https://gist.github.com/MagicWinnie/d8899001c41c851bdc1ae9a10def8fb4}

The scripts were very helpful while debugging and counting the statistics.
The generator creates $n$ random maps following the rules stated in the problem.
The interactor can be used with a solution on any language as it gets a command to run the solution with. Also it receives the directory with generated tests and the variant number. The interactor creates a CSV file with tests' file names, received answers from the solution, and the execution times.
The CSV file then can be used to count the statistics manually or through other programs.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        \multicolumn{2}{c}{} & \multicolumn{2}{|c}{Backtracking} & \multicolumn{2}{|c}{A*} \\
        \cline{3-6}
        \multicolumn{2}{c|}{} & Variant 1 & Variant 2 & Variant 1 & Variant 2 \\
        \hline
        \hline
        \multirow{4}{*}{Time} & Mean, $s$ & 0.096 & 0.099 & 0.078 & 0.086 \\
        \cline{2-6}
        & Mode, $s$ & 0.068 & 0.062 & 0.065 & 0.070 \\
        \cline{2-6}
        & Median, $s$ & 0.111 & 0.098 & 0.079 & 0.073 \\
        \cline{2-6}
        & $\sigma$, $s$ & 0.047 & 0.055 & 0.020 & 0.027 \\
        \hline
        \multirow{6}{*}{Wins} & Count & \multicolumn{4}{c}{914} \\
        \cline{2-6}
        & $\%$ & \multicolumn{4}{c}{91.4} \\
        \cline{2-6}
        & Mean & \multicolumn{4}{c}{914} \\
        \cline{2-6}
        & Mode & \multicolumn{4}{c}{914} \\
        \cline{2-6}
        & Median & \multicolumn{4}{c}{914} \\
        \cline{2-6}
        & $\sigma$ & \multicolumn{4}{c}{0} \\
        \hline
        \multirow{6}{*}{Losses} & Count & \multicolumn{4}{c}{86} \\
        \cline{2-6}
        & $\%$ & \multicolumn{4}{c}{8.6} \\
        \cline{2-6}
        & Mean & \multicolumn{4}{c}{86} \\
        \cline{2-6}
        & Mode & \multicolumn{4}{c}{86} \\
        \cline{2-6}
        & Median & \multicolumn{4}{c}{86} \\
        \cline{2-6}
        & $\sigma$ & \multicolumn{4}{c}{0} \\
    \end{tabular}
    \caption{Comparison of statistics for all algorithms}
    \label{fig:statistics}
\end{figure}

The results in table \ref{fig:statistics} were received by running the interactor on the same 1000 tests for all combinations of algorithms and perception variants.

All of them gave the same answers for the tests.
Therefore, number of wins, number of losses, and their percentages are equal for all columns.
For this reason, mean, mode, median for count of wins/losses are equal to count of wins/losses.
And standard deviations for count of wins/losses are equal to 0.

For counting modes the execution times were rounded to 3 digits after the decimal point.

\subsection{Backtracking (variant 1) compared to A* (variant 1)} \label{backtracking_1_vs_a_star_1}
It is obvious from table \ref{fig:statistics} that A* outperforms Backtracking.
In mean time A* is $\approx 1.2$ times faster, but when we look at values that are not that affected by outliers, then actually A* is faster for $\approx 1.4$ times.
Also it is interesting to look at the standard deviations: it is $\approx 2$ times larger for Backtracking, than for A*.
Which means that A* works for different tests with closer times than Backtracking.
Values of wins and losses were discussed above.
\subsection{Backtracking (variant 2) compared to A* (variant 2)}
It, basically, repeats the information given in subsection \ref{backtracking_1_vs_a_star_1}.
\subsection{Backtracking (variant 1) compared to Backtracking (variant 2)}
Mean time and standard deviation of time for variant 1 is smaller than in variant 2, but other values are larger.
It means that for variant 2 there were some tests that executed with a more larger time, which led to increase in $\sigma$ and mean time.
But generally, variant 2 executed a little bit faster.
\subsection{A* (variant 1) compared to A* (variant 2)}
In A*, variant 2 did not give any time win as every value excpet median of time increased.
This could mean that there is some problem in the implementation, but this should be investigated.

\section{PEAS description}
\subsection{Performance Measure}
The performance measure for Thanos would be reaching the Infinity Stone in the fastest way possible.
\subsection{Environment}
The environment for Thanos would be our map.
\subsubsection{Properties of environment}
\textbf{Partially Observable.} Thanos' vision is limited to his perception zone.

\textbf{Multiple Agent.} The agents are Thanos and Avengers. They all have sensors.

\textbf{Deterministic.} The next state of the map can be determined given the previous state and the action applying.

\textbf{Sequential.} Current decisions in our map can have consequences on future actions: picking up the Shield removes the perception zones of Hulk and Thor.

\textbf{Static.} When Thanos is staying still and is thinking about his actions, the environment does not change.

\textbf{Discrete.} We are operating with snapshots of the map and do not see, for example, Thanos smoothly moving from one cell to another.

\textbf{Known.} All the rules of the environment were given in the problem statement.
\subsection{Actuators}
Thanos can move into adjacent cells, pick up the Shield and the Infinity Stone.
\subsection{Sensors}
Thanos has two variants of his vision (perception zone) that allow him to perceive characters (Avengers, Shield, Infinity Stone).

\section{Impossible maps}
These are some examples of impossible maps found by my solution (from 1000 of total maps generated):

\begin{figure}[H]
    \centering
    \large
    \begin{TAB}(e,0.75cm,0.75cm){|c:c:c:c:c:c:c:c:c|}{|c:c:c:c:c:c:c:c:c|}
        A  & P &   &   &   &   &   &   &  \\
        P & H & P & P & P &   &   & S &  \\
          & P & P & T & P &   &   &   &  \\
        P & P & M & P & P &   &   &   &  \\
          & P & P & P &   &   &   &   &  \\
          &   & P &   &   &   &   &   &  \\
          &   &   &   &   &   &   &   &  \\
          &   &   &   &   &   &   &   &  \\
          &   &   &   & I &   &   &   &  \\
    \end{TAB}
    \caption{Cannot exit start cell}
\end{figure}

\begin{figure}[H]
    \centering
    \large
    \begin{TAB}(e,0.75cm,0.75cm){|c:c:c:c:c:c:c:c:c|}{|c:c:c:c:c:c:c:c:c|}
        A  &   &   &   &   &   & P & P & P \\
          &   &   &   &   & P & P & M & P \\
          &   &   &   &   &   & P & P & P \\
          &   &   & P & P & P &   & P &   \\
          &   &   & P & T & P &   &   &   \\
          &   &   & P & P & P &   &   & I \\
          &   & P &   &   &   &   &   &   \\
          & P & H & P &   &   &   &   &   \\
          &   & P &   &   &   & S &   &   \\
    \end{TAB}
    \caption{Shield and Infinity Stone are unreachable from start}
\end{figure}

\begin{figure}[H]
    \centering
    \large
    \begin{TAB}(e,0.75cm,0.75cm){|c:c:c:c:c:c:c:c:c|}{|c:c:c:c:c:c:c:c:c|}
        A &   &   &   & P & T & P &   &   \\
          &   &   &   & P & P & P &   &   \\
          &   &   &   &   &   &   &   &   \\
          &   &   &   &   &   &   &   &   \\
          &   & P &   &   &   &   &   & S \\
          & P & P & P &   &   & P &   &   \\
        P & P & M & P & P & P & H & P &   \\
          & P & P & P &   &   & P &   &   \\
        I &   & P &   &   &   &   &   &   \\
    \end{TAB}
    \caption{Shield is reachable, but Infinity Stone is surrounded by Captain Marvel}
\end{figure}

\section{Interesting outcomes or maps}
No interesting outcomes or maps were observed.

\end{document}
